{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tareas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Fecha límite de entrega: 9 de octubre, 2020 23:59\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, fixed, widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.interactive import printing\n",
    "printing.init_printing(use_latex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Usando **SimPy** demostrar que \n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\beta_j} \\textbf{J}(\\beta) = \\frac{1}{m}\\sum_{i=1}^{m}\\left(\\hat{y}(x^{(i)}) - y(x^{(i)})\\right) \\cdot x^{(i)}_j\n",
    "$$\n",
    "Para el caso de $\\beta_0, \\beta_1$ en $J(\\beta_0,\\beta_1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0=Symbol('beta_0')\n",
    "beta1=Symbol('beta_1')\n",
    "y_i=Symbol('y_i')\n",
    "x_i=Symbol('x_i')\n",
    "m=Symbol('m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notar que la derivada de una suma es la suma de sus serivadas, por lo tanto resta calcular únicamente\n",
    "# la derivada de uno de los sumandos y ver que coincide con la expresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$\\displaystyle \\left( \\frac{2 \\beta_{0} + 2 \\beta_{1} x_{i} - 2 y_{i}}{2 m}, \\  - \\frac{x_{i} \\left(- \\beta_{0} - \\beta_{1} x_{i} + y_{i}\\right)}{m}\\right)$"
      ],
      "text/plain": [
       "⎛2⋅β₀ + 2⋅β₁⋅xᵢ - 2⋅yᵢ  -xᵢ⋅(-β₀ - β₁⋅xᵢ + yᵢ) ⎞\n",
       "⎜─────────────────────, ───────────────────────⎟\n",
       "⎝         2⋅m                      m           ⎠"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.diff(((2*m)**-1)*(y_i-beta0-beta1*x_i)**2,beta0),sym.diff(((2*m)**-1)*(y_i-beta0-beta1*x_i)**2,beta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el ejemplo de la clase ( i.e. Los archivos `edad.dat` y `altura.dat` contienen las mediciones de las estaturas (en metros) de varios niños entre las edad de 2 y 8 años. Cada _tupla_ de altura y edad, constituyen un ejemplo de entrenamiento $(x^{(i)}, y^{(i)})$ de nuestros datos. Hay $m = 50$ datos para entrenar que usaremos para realizar un modelo de regresión lineal. ) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Grafique $\\textbf{J}(\\beta)$ del ejercicio en $3D$ y en una gráfica de contorno. \n",
    "\n",
    "**(b)** Indique con un punto el valor de $\\textbf{J}(\\beta)$ en la última iteración.\n",
    "\n",
    "**(c)** Modifique el _widget_ para mostrar conforme pasan las iteraciones como el valor de $\\textbf{J}(\\beta)$ se acerca al mínimo en la gráfica de contorno.\n",
    "\n",
    "**(d)** Agrega al _widget_ un control para modificar $\\alpha$ (habrá que agregar el entrenamiento del modelo a la función que estás realizando para este _widget_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "X = np.loadtxt('data/edad.dat')\n",
    "Y = np.loadtxt('data/altura.dat')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  Usando los datos de `chirps.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Chirps/Second \tTemperature (º F)\r\n",
      "20.0 \t88.6\r\n",
      "16.0 \t71.6\r\n",
      "19.8 \t93.3\r\n",
      "18.4 \t84.3\r\n",
      "17.1 \t80.6\r\n",
      "15.5 \t75.2\r\n",
      "14.7 \t69.7\r\n",
      "15.7 \t71.6\r\n",
      "15.4 \t69.4\r\n",
      "16.3 \t83.3\r\n",
      "15.0 \t79.6\r\n",
      "17.2 \t82.6\r\n",
      "16.0 \t80.6\r\n",
      "17.0 \t83.5\r\n",
      "14.4 \t76.3\r\n"
     ]
    }
   ],
   "source": [
    "%cat data/chirps.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('data/chirps.txt')\n",
    "Y = np.loadtxt('data/chirps.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar una regresión lineal. Grafique los datos y el mejor modelo. Explique como llegó a los valores de $\\alpha$. ¿Coinciden con los mostrados en la página web?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegresionLineal:\n",
    "    def __init__(self, alpha=0.3, max_iters=100, tols=0.001):\n",
    "        \"\"\"\n",
    "        Parámetros.\n",
    "        ---------------\n",
    "        alpha = Learning rate\n",
    "        max_iters = Número máximo de iteraciones\n",
    "        tols = definición de convergencia\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.max_iters = max_iters\n",
    "        self.tols = tols\n",
    "        self.breaking_iteration = None\n",
    "        self.historia = {'costo':[], 'beta':[]}  # Con fines de graficación\n",
    "        \n",
    "    def gradientDescent(self, x, y):\n",
    "        \"\"\"\n",
    "        Parámetros:\n",
    "        ---------------\n",
    "        x = vector de entrenamiento de features\n",
    "        y = vector de entrenamiento de variable a predecir (target)\n",
    "        \"\"\"    \n",
    "        \n",
    "        # ajustamos el vector de features\n",
    "        unos = np.ones((x.shape[0], 1))\n",
    "        Xt = X.reshape(x.shape[0], 1)\n",
    "        Xt = np.concatenate((unos, Xt), axis=1)\n",
    "        \n",
    "        i = 0\n",
    "        prep_J = 0\n",
    "        m, n = Xt.shape\n",
    "        self.beta = np.zeros(n) \n",
    "        \n",
    "        while i < self.max_iters:     \n",
    "            # Actualizamos beta\n",
    "            self.beta = self.beta - self.alpha * self.gradiente(Xt, y)\n",
    "            \n",
    "            J = self.costo(Xt, y)\n",
    "            \n",
    "            if abs(J - prep_J) <= self.tols:\n",
    "                print('La función convergió con beta: %s en la iteración %i' % ( str(self.beta), i ))\n",
    "                self.breaking_iteration = i\n",
    "                break\n",
    "            else:\n",
    "                prep_J = J\n",
    "            \n",
    "            self.historia['costo'].append(J)\n",
    "            self.historia['beta'].append(self.beta)                \n",
    "            i += 1\n",
    "    \n",
    "    def hipotesis(self, x):\n",
    "        return np.dot(x, self.beta)\n",
    "    \n",
    "    def costo(self, x, y):\n",
    "        m = x.shape[0]\n",
    "        error = self.hipotesis(x) - y\n",
    "        return np.dot(error.T, error) / (2 * m) \n",
    "    \n",
    "    def gradiente(self, x, y):\n",
    "        m = x.shape[0]\n",
    "        error = self.hipotesis(x) - y        \n",
    "        return np.dot(x.T, error) / m   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 30 into shape (15,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-20f61cd1dc94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRegresionLineal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradientDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-5a0e82fc57fb>\u001b[0m in \u001b[0;36mgradientDescent\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# ajustamos el vector de features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0munos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 30 into shape (15,1)"
     ]
    }
   ],
   "source": [
    "lm=RegresionLineal(alpha=0.003,max_iters=100000,tols=.000001)\n",
    "lm.gradientDescent(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**NOTA**: Datos obtenidos de [aquí](http://mathbits.com/MathBits/TISection/Statistics2/linearREAL.htm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Usando los datos del [cuarteto de Anscombe](http://en.wikipedia.org/wiki/Anscombe%27s_quartet) Calcule la regresión lineal ¿Qué sucede?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use el archivo `radioactive_decay.dat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#time   N_(remaining)\r\n",
      "0.0\t10.48\r\n",
      "1.0\t7.54\r\n",
      "2.0\t5.49\r\n",
      "3.0\t4.02\r\n",
      "4.0\t2.74\r\n",
      "5.0\t2.02\r\n",
      "6.0\t1.50\r\n",
      "7.0\t1.09\r\n",
      "8.0\t0.68\r\n",
      "9.0\t0.57\r\n",
      "10.0\t0.37\r\n",
      "11.0\t0.31\r\n",
      "12.0\t0.19\r\n",
      "13.0\t0.15\r\n",
      "14.0\t0.13\r\n",
      "15.0\t0.11\r\n"
     ]
    }
   ],
   "source": [
    "%cat dat a/radioactive_decay.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Grafique los datos ¿Qué forma tienen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** ¿Qué transformación se le ocurre para linearizarlos? Explique y grafique de nuevo. Guarde los datos transformados en un archivo llamado `transform_radioactive_decay.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Aplique la regresión lineal a este conjunto de datos transformado, leyendo los datos del archivo recién creado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** ¿Cuáles son los valores de $\\beta$ que mejor ajustan? ¿Cuáles son el espacio sin transformar? Explique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
