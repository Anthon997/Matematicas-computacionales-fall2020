{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['beta', 'det', 'eye', 'exp', 'cbrt', 'interactive', 'tanh', 'diff', 'take', 're', 'var', 'transpose', 'multinomial', 'nan', 'invert', 'partition', 'sin', 'deprecated', 'Line2D', 'Circle', 'power', 'trunc', 'source', 'lcm', 'test', 'ifft', 'sign', 'prod', 'flatten', 'seterr', 'solve', 'roots', 'conjugate', 'tan', 'cos', 'fft', 'vectorize', 'Polygon', 'zeros', 'plot', 'Number', 'product', 'cosh', 'gcd', 'poly', 'array', 'minimum', 'sqrt', 'pi', 'reshape', 'mod', 'sinc', 'plotting', 'binomial', 'trace', 'diag', 'floor', 'sinh', 'maximum', 'log', 'add', 'gamma', 'ones']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, fixed, widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos un conjunto $m$ de datos de entrada $\\textbf{x}$ (en aprendizaje de máquina se les conoce como _features_) y sus datos dependientes, $\\textbf{y}$ (_target_ en aprendizaje de máquina). A este conjunto $(x^{(i)}, y^{(i)})$, le llamamos conjunto de entrenamiento. Queremos desarrollar un modelo $\\hat{\\textbf{y}}$ que aproxime el valor de $\\textbf{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera aproximación es intentar una aproximación de forma lineal, conocida como _regresión lineal_, de la forma\n",
    "\n",
    "$$\n",
    "\\hat{\\textbf{y}} = \\mathbf\\beta_0 + \\mathbf\\beta_1 \\textbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde (si recuerdan Geometría Analítica) $\\beta_0$ es el _interceptor_ de la recta $\\hat{\\textbf{y}}$ y $\\beta_1$ es la _pendiente_ de la recta. A $\\hat{\\textbf{y}}$ se le conoce también como _hipótesis_ y se le puede denotar con la variable $\\textbf{h}$. Si definimos que $x_0 \\equiv 1$, podemos escribir la _hipótesis_ de manera más compacta:\n",
    "\n",
    "$$\n",
    "\\hat{\\textbf{y}} = \\sum_{j=0}^n \\beta_j x_j = \\mathbf{\\beta}^T\\textbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta notación, podemos extender el formalismo a más dimensiones (en este caso $n$).\n",
    "\n",
    "Una posible definición de **mejor** es que el modelo (el cual está determinado por $\\vec\\beta$) minimice la suma de las diferencias entre el valor actual $\\textbf{y}$ y el predicho $\\hat{\\textbf{y}}$ (a esta diferencia se le conoce como _error en la predicción_), en otras palabras _minimizar la suma del cuadrado de los residuos_. La función a minimizar se conoce en aprendizaje de máquina como _función de costo_ $\\textbf{J}$. Debido a que tenemos varios pares $(x_i, y_i)$, la función costo a minimizar es el _error cuadrático promedio_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{J}(\\beta_0, \\beta_1) = \\frac{1}{2n}\\sum_{(x^{(i)}, y^{(i)}) \\in X \\times Y} (y^{(i)} - \\hat{y}^{(i)}(x^{(i)}))^2 = \\frac{1}{2n}\\sum_{(x^{(i)}, y^{(i)}) \\in X \\times Y} (y^{(i)} - \\beta_0 - \\beta_1 x^{(i)})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Matriz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-b43bdf86e87b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMatriz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x:6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y:6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'j'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Matriz' is not defined"
     ]
    }
   ],
   "source": [
    "from sympy.abc import i, n,x,y\n",
    "w = Matriz\n",
    "symbols('x:6')[1:]\n",
    "symbols('y:6')[1:]\n",
    "j = Function('j')\n",
    "b0 = Symbol('beta_0')\n",
    "b1 = Symbol('beta_1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{\\substack{1 \\leq x \\leq n\\\\1 \\leq y \\leq n}} \\left(- \\beta_{0} - \\beta_{1} x + y\\right)^{2}$"
      ],
      "text/plain": [
       "Sum((-beta_0 - beta_1*x + y)**2, (x, 1, n), (y, 1, n))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = Sum((y-b0-b1*x)**2, (x, 1, n), (y, 1, n))\n",
    "j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\sum_{i=1}^{n} \\left(2 \\beta_{0} + 2 \\beta_{1} {x}_{i} - 2 {y}_{i}\\right)}{2 n}$"
      ],
      "text/plain": [
       "Sum(2*beta_0 + 2*beta_1*x[i] - 2*y[i], (i, 1, n))/(2*n)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_ = diff(j, b0)\n",
    "j_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Usando **SimPy** demostrar que \n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\beta_j} \\textbf{J}(\\beta) = \\frac{1}{m}\\sum_{i=1}^{m}\\left(\\hat{y}(x^{(i)}) - y(x^{(i)})\\right) \\cdot x^{(i)}_j\n",
    "$$\n",
    "Para el caso de $\\beta_0, \\beta_1$ en $J(\\beta_0,\\beta_1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el ejemplo de la clase ( i.e. Los archivos `edad.dat` y `altura.dat` contienen las mediciones de las estaturas (en metros) de varios niños entre las edad de 2 y 8 años. Cada _tupla_ de altura y edad, constituyen un ejemplo de entrenamiento $(x^{(i)}, y^{(i)})$ de nuestros datos. Hay $m = 50$ datos para entrenar que usaremos para realizar un modelo de regresión lineal. ) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Grafique $\\textbf{J}(\\beta)$ del ejercicio en $3D$ y en una gráfica de contorno. \n",
    "\n",
    "**(b)** Indique con un punto el valor de $\\textbf{J}(\\beta)$ en la última iteración.\n",
    "\n",
    "**(c)** Modifique el _widget_ para mostrar conforme pasan las iteraciones como el valor de $\\textbf{J}(\\beta)$ se acerca al mínimo en la gráfica de contorno.\n",
    "\n",
    "**(d)** Agrega al _widget_ un control para modificar $\\alpha$ (habrá que agregar el entrenamiento del modelo a la función que estás realizando para este _widget_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  Usando los datos de `chirps.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
